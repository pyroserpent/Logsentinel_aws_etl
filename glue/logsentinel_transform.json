{
	"jobConfig": {
		"name": "logsentinel_transform",
		"description": "",
		"role": "arn:aws:iam::615299776325:role/service-role/AWSGlueServiceRole",
		"command": "glueetl",
		"version": "5.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 480,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "logsentinel_transform.py",
		"scriptLocation": "s3://aws-glue-assets-615299776325-us-east-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2025-03-14T18:42:15.814Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-615299776325-us-east-1/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-615299776325-us-east-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"maintenanceWindow": null,
		"pythonPath": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "from awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom awsglue.context import GlueContext\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.dynamicframe import DynamicFrame\r\nimport boto3\r\n\r\n# Initialize AWS Glue and Spark\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\n\r\n# Read data from S3\r\nraw_data_collection = glueContext.create_dynamic_frame.from_catalog(\r\n    database=\"logsentinel_db\",\r\n    table_name=\"raw_logs\"\r\n)\r\n\r\n\r\n# Ensure we are working with a single DynamicFrame\r\nif isinstance(raw_data_collection, list):  # If it's a collection, get the first frame\r\n    raw_data_collection = raw_data_collection[0]\r\n\r\n# Transform: Clean Data (Example Transformation)\r\ncleaned_data = ApplyMapping.apply(\r\n    frame=raw_data_collection,  # ✅ FIX: Use the correct variable name\r\n    mappings=[\r\n        (\"timestamp\", \"string\", \"timestamp\", \"string\"),\r\n        (\"level\", \"string\", \"level\", \"string\"),\r\n        (\"message\", \"string\", \"message\", \"string\"),\r\n        (\"service\", \"string\", \"service\", \"string\"),\r\n    ]\r\n)\r\n\r\n\r\n# Convert to DataFrame\r\ndf_cleaned = raw_data_collection.toDF()\r\n\r\n# Write processed logs to S3\r\noutput_path = \"s3://logsentinel-logs/processed_logs/\"\r\ndf_cleaned.write.mode(\"append\").parquet(output_path)\r\n\r\nprint(\"✅ AWS Glue ETL Job Completed Successfully!\")\r\n"
}